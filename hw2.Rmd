---
title: "BIOST 544 Homework 2"
author: "Yichen Lu"
date: "11/3/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE, cache = TRUE)
knitr::opts_knit$set(root.dir = "C:/Users/luy85/Google Drive (luyichen1994@gmail.com)/UW Seattle/Fall20/BIOST544/")
options(digits = 3)
library(ggplot2)
library(dplyr)
library(knitr)
```

```{r, echo = FALSE}
rm(list = ls())
dt <- read.delim("HW2-adaptive-trial.txt", sep = ",")
```

1. Suppose we are comparing a new treatment to standard-of-care. We run a randomized clinical trial (with basic simple randomization), and would like to assess if treatment is more effective than control (using a binary outcome — response vs non-response). Suppose efficacy is assessed by the difference in response proportion between new-treatment and standard-of-care.

Please write a function that takes in data from a clinical trial run as above (a matrix with two columns: tx for treatment assignment, and outcome, with outcome=1 indicating response), and runs a permutation/re-randomization test to evaluate if the data are consistent with the hypothesis that standard-of-care is at least as effective as new-treatment.

<span style="color: blue"> The following function `simulate.perm.trial` takes in a data set, permute the treatment assignment and calculate the difference in proportion of participants with response compared to non-respondents in the new permuted data set.<span>

```{r}
simulate.perm.trial <- function(data){
  perm <- sample(1:nrow(data), replace = FALSE)
  perm.data <- data
  perm.data$tx = data$tx[perm]
  
  perm.mean.diff <- with(perm.data, mean(outcome[tx == 1]) - mean(outcome[tx == 0]))
  return(perm.mean.diff)
}
```

2a. Please write a function that will take in data from a trial run as above (ie. a matrix with one column tx of treatment assignments, one column outcome of binary outcomes, and one column order of enrollment order) and run a re-randomization test. The test should assess if the observed difference in response proportions is consistent with the hypothesis that standard-of-care is at least as effective as the new-treatment.

<span style="color: blue"> The following function `simulate.adapt.trial` takes in a data set, permute the treatment assignment using the adaptive randomization method and calculate the difference in proportion of participants with response compared to non-respondents in the new permuted data set. For the first participant, we assign them to new vs old treatment based on the probability of new treatment being 0.5 and their outcome remains the same as in the input data set. We then update the probability of new treatment using the adaptive formula and use this to randomize the second participant to either new vs old treatment, the outcome for this participant remains the same as in the original data set. We do for each participants. <span>

```{r}
simulate.adapt.trial <- function(data){
  s_new = 0
  f_new = 0
  s_old = 0
  f_old = 0
  p_new = 0.5
  n = s_new + f_new + f_old + s_old # current number of patients
  N = nrow(data)
  adapt.data <- c()
  
  for (n in 1:N){
    adapt.tx <- rbinom(1, 1, p_new)
    adapt.outcome <- data[data$order == n,]$outcome # extract original outcome
    adapt.data <- rbind(adapt.data, 
                        cbind("tx" = adapt.tx, "outcome" = adapt.outcome, "order" = n))
    if (adapt.tx == 1){ # new treatment
      if (adapt.outcome == 1){ # response
        s_new = s_new + 1
      } else { # failure
        f_new = f_new + 1
      }
    } else { # old treatment
      if (adapt.outcome == 1){ # response
        s_old = s_old + 1
      } else { # failure
        f_old = f_old + 1
      }
    }
    p_new <- (1 + 3 * (s_new + f_old))/(2 + 3 * n)
    n = n + 1
  }
  adapt.mean.diff <- with(as.data.frame(adapt.data), mean(outcome[tx == 1]) - mean(outcome[tx == 0]))
  return(adapt.mean.diff)
}
``` 

2b. Please read in the data; and, using your function from (2a), evaluate if the data are consistent with the hypothesis that standard-of-care is at least as effective as the new treatment.

<span style="color: blue"> We replicate the permutation under the adaptive scheme for 1000 times. We get a p-value of 0.208 and fail to reject the null hypothesis that standard-of-care is at least as effective as the new treatment at a significance level of 0.05. <span>

```{r}
nsim = 1000
obs.mean.diff <- with(dt, mean(outcome[tx == 1]) - mean(outcome[tx == 0])) # orig diff

adapted.stats <- data.frame(replicate(nsim, simulate.adapt.trial(dt)))
colnames(adapted.stats) <- "adapt.mean.diff"
mean(adapted.stats > obs.mean.diff)
```

3. Now suppose a collaborator provided the data, but forgot to say that they were generated using an adaptive trial. In this case we would likely accidentally analyze our data
using the function written in (1). How does the sampling distribution of $\hat{\pi}_{new}$ − $\hat{\pi}_{old}$ generated from the simple permutations in (1) compare to the sampling distribution generated using our adaptive re-randomization from the function in (2a)?

<span style="color: blue"> We replicate the permutation using method from (1) for 1000 times. We get a p-value < 0.05 and reject the null hypothesis that standard-of-care is at least as effective as the new treatment at a significance level of 0.05. <span>

```{r}
permuted.stats <- data.frame(replicate(nsim, simulate.perm.trial(dt)))
colnames(permuted.stats) <- "perm.mean.diff"
mean(permuted.stats > obs.mean.diff)
```

<span style="color: blue"> Both sampling distributions are right skewed. Compared to the sampling distribution of $\hat{\pi}_{new}$ − $\hat{\pi}_{old}$ generated from the simple permutations, the sampling distribution generated using adaptive re-randomization is more flat and spread out. It has more weight to the value equivalent or larger than the observed difference between proportion of success in the new treatment group compared to the old treatment group. <span>

```{r, echo = FALSE}
ggplot(permuted.stats, aes(x=perm.mean.diff, y=..density..)) +
  geom_histogram(alpha=0.5, position="identity")+
  geom_density() + geom_vline(xintercept=obs.mean.diff, colour = "orange") +
  xlim(0, 0.6) + ylim(0, 25) +
  labs(title="Effectiveness of new vs old treatment using simple randomization",
       x ="Prop of successes on the new - old", y = "Density")

ggplot(adapted.stats, aes(x=adapt.mean.diff, y=..density..)) +
  geom_histogram(alpha=0.5, position="identity")+
  geom_density() + geom_vline(xintercept=obs.mean.diff, colour = "orange") +
  xlim(0, 0.6) + ylim(0, 25) +
  labs(title="Effectiveness of new vs old treatment using daptive re-randomization",
       x ="Prop of successes on the new - old", y = "Density")
```